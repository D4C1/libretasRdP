{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales hacia adelante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta libreta vamos a realizar las funciones necesarias para entrenar y predecir utilizando uno red neuronal hacia adelante multicapa, con función de activación logística en *todas* las neuronas de las capas ocultas. Esta libreta no pretende sustituir a las explicaciones en clase o a unas notas sobre redes neuronales. Aqui se asume que ustedes ya tienen una idea general de las redes neuronales, que comprenden las ecuaciones de aprendizaje como las obtuvimos en clase, así como los algoritmos básicos. En esta libreta *solamente* nos vamos a centrar en los aspectos de implementación.\n",
    "\n",
    "Para empezar esta libreta, necesitaremos algunas de las funciones que ya programamos en libretas pasadas, las cuales adjuntamos a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import Image \n",
    "\n",
    "\n",
    "def obtiene_medias_desviaciones(x):\n",
    "    \"\"\"\n",
    "    Obtiene las medias y las desviaciones estandar atributo a atributo.\n",
    "    \n",
    "    @param x: un ndarray de dimensión (T, n) donde T es el númro de elementos y n el número de atributos\n",
    "    @return: medias, desviaciones donde ambos son ndarrays de dimensiones (n,) con las medias y las desviaciones \n",
    "             estandar respectivamente.\n",
    "    \n",
    "    \"\"\"\n",
    "    return x.mean(axis=0), x.std(axis=0)\n",
    "\n",
    "def normaliza(x, medias, desviaciones):\n",
    "    \"\"\"\n",
    "    Normaliza los datos x\n",
    "\n",
    "    @param x: un ndarray de dimensión (T, n) donde T es el númro de elementos y n el número de atributos\n",
    "    @param medias: ndarray de dimensiones (n,) con las medias con las que se normalizará\n",
    "    @param desviaciones: ndarray de dimensiones (n,) con las desviaciones con las que se normalizará\n",
    "    \n",
    "    @return: x_norm un ndarray de las mismas dimensiones de x pero normalizado\n",
    "    \n",
    "    \"\"\"\n",
    "    return (x - medias) / desviaciones\n",
    "\n",
    "\n",
    "def logistica(z):\n",
    "    \"\"\"\n",
    "    Calcula la función logística para cada elemento de z\n",
    "    \n",
    "    @param z: un ndarray\n",
    "    @return: un ndarray de las mismas dimensiones que z\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Calculo de la regresión softmax\n",
    "    \n",
    "    @param z: ndarray de dimensión (T, K) donde z[i, :] es el vector de aportes lineales de el objeto i    \n",
    "    @return: un ndarray de dimensión (T, K) donde cada columna es el calculo softmax de su respectivo vector de entrada.\n",
    "    \n",
    "    \"\"\"\n",
    "    y_hat = np.exp(z)\n",
    "    return y_hat / y_hat.sum(axis=1).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Especificando una red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, para poder hacer una red neuronal, tenemos que determinar cierta información. Por el momento, y para efecto de la libreta, vamos a mantenernos en un esquema estructurado/funcional, y más adelante vamos a generalizar la mayoría de los métodos utilizados en forma de objetos.\n",
    "\n",
    "La información importante que debemos de tener en cuenta cuando hacemos un sistema de redes neuronales es:\n",
    "\n",
    "- Cuantas capas de neuronas tiene la red neuronal, $L$.\n",
    "- Cuantas neuronas va a tener cada capa $[n_0, n_1, \\ldots, n_L]$, donde $n_0$ es el número de entradas y $n_L$ el número de salidas.\n",
    "- Cual es el tipo de salida de mi red neuronal (lineal, logística o softmax)\n",
    "- Los valores con los que se normalizan los datos de entrada a la red neuronal (para el aprendizaje en una red neuronal es muy importante que los valores de entrada estén normalizados).\n",
    "\n",
    "Una vez que se establecen estos valores, es necesario generar una lista de matrices $[W^{(1)}, \\ldots, W^{(L)}]$ donde $W^{(l)}$ es una matriz de dimensiones $(n_l, n_{l-1} + 1)$ de parámetros o pesos. Como vimos en clase, si se inicializan los valores de las entradas de $W^{(l)}$ iguales, es equivalente a tener una sola neurona en esa capa, por lo que es necesario que estos valores sean diferentes. \n",
    "\n",
    "En clase vimos que, para efectos de un mejor aprendizaje, es importante que los valores de entrada se encientren en la zona donde casua más variacion la función logística. Para esto, se espera que en general la suma de los pesos multiplicados por las entradas correspondientes a la capa se encuentren en el rango de $(-1, 1)$. Si asumimos que las entradas a cada neurona están normalizadas (esto es, entre 0 y 1), entonces los pesos deberían ser valores entre $(-\\sqrt{n_{l-1}}, \\sqrt{n_{l-1}})$ con el fin que la suma se encuentre en la región donde más cambios ocurren en la función logística. \n",
    "\n",
    "Vamos a generar y guardar esta información en un diccionario (junto con el resto de la información que requeriramos para tener una red neuronal completamente definida. Al principio los valores de normalización no cuentan ya que estos se deben inicializar al comienzo del aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1. Completa el código de la función de inicialización para los pesos de las matrices de pesos (10 puntos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso la prueba\n"
     ]
    }
   ],
   "source": [
    "def inicializa_red_neuronal(capas, neuronas_por_capa, tipo):\n",
    "    \"\"\"\n",
    "    Inicializa una red neuronal como un diccionario de datos\n",
    "    \n",
    "    @param capas: Un número entero con el número total de capas. Minimo 3 (una de entrada, una oculta, una de salida).\n",
    "    @param neuronas_por_capa: Una lista de enteros donde el primer elemento es el número de entradas\n",
    "                              y el último el número de salidas, mientras que los intermedios son\n",
    "                              el númerode neuronas en cada capa oculta.\n",
    "    @param tipo: Un string entre {'lineal', 'logistica', 'softmax'} con el tipo de salida de la red.\n",
    "    \n",
    "    @return: Un diccionario tal que\n",
    "             - dicc['capas'] = capas\n",
    "             - dicc['nxc'] = neuronas_por_capas\n",
    "             - dicc['tipo'] = tipo\n",
    "             - dicc['thetas'] = lista de matrices de parámetros\n",
    "             - dicc['medias'] = lista de medias de cada atributo\n",
    "             - dicc['std'] = lista de desviaciones estandard de cada atributo\n",
    "             \n",
    "    \"\"\"\n",
    "    if capas != len(neuronas_por_capa):\n",
    "        raise ValueError('El número de capas no corresponde con la lista de las neuronas por capa')\n",
    "    dicc = {'capas': L, 'nxc': neuronas_por_capa, 'tipo': tipo}\n",
    "    dicc['medias'] = np.zeros(neuronas_por_capa[0])\n",
    "    dicc['std'] = np.ones(neuronas_por_capa[0])\n",
    "    \n",
    "    lista_Thetas = []\n",
    "    for l in range(1, capas + 1):\n",
    "        lista_thetas.append(inicializa_Theta(dicc['nxc'][l - 1], dicc['nxc'][l]))\n",
    "    dicc['thetas'] = lista_Thetas\n",
    "    \n",
    "    return dicc\n",
    "\n",
    "def inicializa_Theta( n_lm1, n_l):\n",
    "    \"\"\"\n",
    "    Inicializa una matriz de valores aleatorios Theta\n",
    "    \n",
    "    @param n_lm1: número de neuronas en la capa l-1 (entero)\n",
    "    @param n_l: número de neuronas en la capa l (entero)\n",
    "    \n",
    "    @return: Un ndarray de dimensión (n_l, n_lm1 + 1) donde las entradas son número aleatorios\n",
    "             entre -sqrt(n_lm1) y sqrt(n_lm1)\n",
    "             \n",
    "    \"\"\"\n",
    "    #------------------------------------------------------------------------\n",
    "    # Agregua aqui tu código\n",
    "    return 2.0 * (np.random.random((n_l, n_lm1 + 1)) - 0.5) / np.sqrt(n_lm1)\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "def test_inicializa_theta():\n",
    "    #Vamos a hacer 1000 pruebas aleatorias que nos aseguremos que se cumpleen con las especificaciones\n",
    "    for _ in range(1000):\n",
    "        n0 = np.random.randint(1, 20)\n",
    "        n1 = np.random.randint(1, 20)\n",
    "        Theta1 = inicializa_Theta( n0, n1)\n",
    "        assert Theta1.shape == (n1, n0 + 1)  # Las dimensiones son correctas\n",
    "        assert Theta1.max() < np.sqrt(n0)    # La cota máxima se respeta\n",
    "        assert Theta1.min() > -np.sqrt(n0)   # La cota mínima se respeta\n",
    "        assert np.abs(Theta1).sum() > 0      # No estamos inicializando a 0\n",
    "    return \"Paso la prueba\"\n",
    "\n",
    "print test_inicializa_theta()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, si tenemos una red neuronal, la información contenida en el diccionario es toda la información específica que se necesita para la predicción, el aprendizaje, o el reaprendizaje de una red ya especificada. \n",
    "\n",
    "Como entrenar una red es algo lento y tedioso, y normalmente cuando hacemos un método de aprendizaje, lo que queremos es poder utilizarlo después para predecir un conjunto de datos no etiquetados previamente, es normal que guardemos en un archivo la información específica a la red neuronal, y despues la recuperemos en otra sesión, otro día, o en otra computadora para hacer la predicción.\n",
    "\n",
    "Una manera de guardar datos, funciones y objectos de Python en disco es utilizando el módulo ``pickle`` (o su versión compilada para mayor velocidad ``cPickle``). Este modulo permite guardar una serie de objetos de python en forma secuencial en un archivo binario, y luego recuperarlos. Notese que este métdo es diferente a ``np.load``y ``np.savez``, ya que estos solo permiten guardar (y recuperar) una serie de ndarrays únicamente. \n",
    "\n",
    "Vamos entonces a hacer dos funciones muy simples ``guarda_objeto`` y ``carga_objeto``, que utilizaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasa la prueba\n"
     ]
    }
   ],
   "source": [
    "def guarda_objeto(archivo, objeto):\n",
    "    \"\"\"\n",
    "    Guarda un objeto de python en el archivo \"archivo\". Si el archivo existe, sera reemplazado sin \n",
    "    preguntas, al puro estilo mafioso.\n",
    "    \n",
    "    @param archivo: string con el nombre de un archivo (aunque no exista)\n",
    "    @param objeto: Un objeto de python para ser guardado\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(archivo, 'wb') as arch:\n",
    "        cPickle.dump(objeto, arch, -1)\n",
    "        arch.close()\n",
    "        \n",
    "def carga_objeto(archivo):\n",
    "    \"\"\"\n",
    "    Carga el primer (y se asume que único) objeto contenido en el archivo 'archivo' que debe de ser tipo cPickle.\n",
    "    \n",
    "    @param archivo: string con el nombre de un archivo tipo pickle\n",
    "    @return: El primer objeto dentro del picke\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(archivo, 'rb') as arch:\n",
    "        objeto = cPickle.load(arch)\n",
    "        arch.close()\n",
    "        return objeto\n",
    "    \n",
    "def test_archivo():\n",
    "    \"\"\"\n",
    "    Prueba, para esto vamos a cargar o a leer (o ambas cosas) un objeto en un archivo\n",
    "    \n",
    "    Por favor, borrar el archivo cada vez que se pruebe, o para probar la lectura y la escritura\n",
    "    \n",
    "    \"\"\"\n",
    "    temp = [range(100), 'prueba', True]\n",
    "    guarda_objeto('prueba.pkl', temp)\n",
    "    temp =[10, 'no prueba', False]\n",
    "    otro = carga_objeto('prueba.pkl')\n",
    "    assert len(otro[0]) == 100\n",
    "    assert otro[1] == 'prueba'\n",
    "    assert otro[-1]\n",
    "    \n",
    "    return \"Pasa la prueba\"\n",
    "\n",
    "print test_archivo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculando el costo (y por lo tanto feed-forward)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumamos que tenemos una red neuronal ya inicializada, y que la vamos a utilizar para calcular el costo de una solución. Como vimos en clase, el costo de la solución depende del tipo de neuronas de salida (que son en realidad la etapa de clasificación). Así, para calcular el costo, es necesario calcular la salida de la red neuronal.\n",
    "\n",
    "Recordemos que el algoritmo para realizar la alimentación hacia adelante de una red neuronal el algoritmo es el siguiente:\n",
    "\n",
    "1. Inicializa $a^{(0)}$ asignandole los valores de las entradas\n",
    "\n",
    "2. Por cada capa $l$ de 1 a $L-1$:\n",
    "\n",
    "    1. Se calcula el valor de $z^{(l)}$ como $$z^{(l)} = \\Theta^{(l-1)} a_e^{(l-1)},$$ donde $\\Theta^{(l-1)}$ es la \n",
    "       matriz de pesos de la capa $l-1$ a la capa $l$, y $a_e{(l-1)}$ es $a^{(l-1)}$ extendida con un 1 al principio \n",
    "       el vector.\n",
    "       \n",
    "    2. Se calcula $a^{(l)}$ como $$a^{(l)} = g(z^{(l)}),$$ donde $g$ es la función de activación (en nuestro caso hemos \n",
    "       decidido utilizar la función logística, pero podríamos tener otras funciones de activación).\n",
    "\n",
    "3. Se calcula el valor de $z^{(L)}$ como $$z^{(L)} = \\Theta^{(L-1)} a_e^{(L-1)}.$$ \n",
    "\n",
    "4. Se calcula $a^{(L)}$ de acuerdo a la función de activación dependiendo del tipo de salida:\n",
    "\n",
    "    * Si `tipo = 'logistica'` entonces se utiliza la regresión logística (una sola neurona en la capa de salida).\n",
    "    * Si `tipo = 'lineal'` entonces $a^{(L)} = z^{(L)}$.\n",
    "    * Si `tipo = 'softmax'` entonces $a^{(L)} = softmax(z^{(L)}).$\n",
    "\n",
    "5. La salida de la red es $a^{(L)}$.\n",
    "\n",
    "Aqui hay que tomar en cuenta varias cosas: en primer lugar, la activación de todas las neuronas en todas las capas, y para todos los datos los necesitamos para realizar el algoritmo de *backpropagation*, por lo que se requiere guardarlos. Igualmente, no es eficiente calcular todos los pasos dato por dato, ya que eso lo haría muy, pero muy lento. Así que vamos a aporvechar que los datos vienen en forma de un *ndarray* de numpy y haremos todos los calculos en forma matricial tal como los vimos en clases. \n",
    "\n",
    "Sea $X$ la matriz de valores de entrada, entonces $A^{0} = X^T$ es una lista de vectores columna donde cada columna es $a^{(0)}$ para el objeto correspondiente. Así, los calculos se pueden realizar columna por columna, y simplemente\n",
    "$$ \n",
    "Z^{(l)} = \\Theta^{(l-1)}A_e^{(l-1)},\n",
    "$$\n",
    "donde $A_e^{(l-1)}$ es $A^{(l-1)}$ agregandole un 1 al inicio de cada vector (o lo que es lo mismo, agregandole un renglon de unos al inicio). Si procedemos de esta forma, entonces es importante recordar que al final $\\hat{Y} = (A^{(L)})^T$, ya que para la salida cada renglon es un dato diferente (de acuerdo a nuestra convención desde los otros algoritmos que hamos utilizado), mientras que internamente,para la red neuronal, cada columna proviene de un objeto diferente.\n",
    "\n",
    "Por último, es importante recordar que la normalización es muy importante para las redes neuronales, especialmente si se utiliza el método de descenso de gradiente, por lo que es importante normalizar los datos antes de que sean utilizados, con la información de normalización que se conoce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2. Completa el código de la función de *feedforward* para una red neuronal ya establecida (30 puntos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feedforward(X, red_neuronal):\n",
    "    \"\"\"\n",
    "    Calcula la salida estimada para los valores de `X` utilizando red_neuronal\n",
    "    \n",
    "    @param X: ndarray de shape (T, n) donde T es el número de ejemplos y n el número de atributos\n",
    "    @param red_neuronal: Estructura de datos de una red neuronal inicializada con la función `inicializa_red_neuronal``\n",
    "    \n",
    "    @return: `Y_est`, `lista_A`, donde `Y_est` es un ndarray de shape (T, k) donde T es el número de objetos y k es \n",
    "             el número de salidas (neuronas de salida de la red neuronal).\n",
    "             \n",
    "    \"\"\"\n",
    "    # Primero hay que normalizar los datos de entrada\n",
    "    # ----------Agragar código aqui -----------------\n",
    "    xnorm = normaliza(x, red_neuronal['medias'], red_neuronal['std'])\n",
    "    \n",
    "    # Despues es necesario inicializar A^{(0)}\n",
    "    # ----------Agragar código aqui -----------------\n",
    "    lista_A = []\n",
    "    lista_A.append(xnorm.T)\n",
    "    \n",
    "    # Despues vamos a hacer lo propio por cada capa hasta antes de la última\n",
    "    for l in range(1, red_neuronal['capas']):\n",
    "        # Calcula A_e^{l-1}, Z^{(l)} y por último A^{(L)} \n",
    "        # y agrega A^{(L)} a lista_A.        \n",
    "        # (puede ser todo junto o por partes)\n",
    "        # ----------Agragar código aqui -----------------\n",
    "        lista_A.append( logistica(red_neuronal['thetas'][l-1].dot(extendida(lista_A[l-1]))))\n",
    "                                      \n",
    "    \n",
    "def prueba_feedforward():\n",
    "    \"\"\"\n",
    "    Función para validar la función de fedforward (cada paso)\n",
    "\n",
    "    \"\"\"\n",
    "    red_neuronal = inicializa_red_neuronal(2, neuronas_por_capa, tipo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con  la función de feedforward desarrollada, entonces podemos hacer una función para calcular el costo final, la cual depende de las salidas `Y`, de las salidas estimadas por la red neuronal `Y_est`, y del tipo de salida. Igualmente, para agregar la regularización, es necesario un valor `lammbda` de regularización y los parámetros de la red neuronal (`lista_thetas` de la estructura de datos de la red neuronal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3: Completa el código de la función de costo (10 puntos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def costo(Y, Y_est, tipo, lammbda=0, thetas=None):\n",
    "    \"\"\"\n",
    "    Calcula la función de costo de una red neuronal con regularización (por default 0)\n",
    "    \n",
    "    @param Y\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculando el gradiente con el algoritmo de *Backpropagation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es este apartado se genera el gradiente utilizando simplemente el algoritmo de backpropagarion y se prueba con una red neuronal ya hecha anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aprendizaje con descenso de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se realiza el decenso de gradiente, incluidos\n",
    "\n",
    "1. Inercia\n",
    "2. Parada temprana\n",
    "\n",
    "y por último se prueba en un problema sencillo (aunque no tan sencillo pues, pa que tenga interés)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aprendizaje por función de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este apartado es muy rápido, solo se usa para ver como se enrrolla y se desenrrolla un vector de parámetros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
